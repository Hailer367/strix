name: Strix Remote Tool Server

on:
  workflow_dispatch:
    inputs:
      server_timeout:
        description: 'Server timeout in minutes (default: 120)'
        required: false
        default: '120'
        type: string
  workflow_call:
    # Can be called from other workflows

concurrency:
  group: strix-server
  cancel-in-progress: false  # Don't cancel - we want one server running

env:
  SERVER_PORT: '50051'
  SERVER_TIMEOUT: 120

jobs:
  start-server:
    name: Start Remote Tool Server
    runs-on: ubuntu-latest
    permissions:
      contents: read
      # Note: Secret updates are done via API with SERVER_TOKEN, not workflow permissions

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Cloudflared
        run: |
          set -euo pipefail
          echo "::group::Installing Cloudflared"
          curl -L --output cloudflared.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
          sudo dpkg -i cloudflared.deb
          rm cloudflared.deb
          echo "Cloudflared installed: $(cloudflared --version)"
          echo "::endgroup::"

      - name: Install Dependencies
        run: |
          set -euo pipefail
          echo "::group::Installing Python dependencies"
          pip install -q poetry
          poetry config virtualenvs.create false
          
          # Try poetry install, but don't fail if it has issues
          if ! poetry install --no-interaction 2>&1; then
            echo "::warning::Poetry install had issues, installing dependencies manually..."
            # Install core dependencies manually
            pip install jinja2 httpx tenacity requests pydantic rich docker textual xmltodict
          fi
          
          # Install gRPC dependencies and PyNaCl for secret encryption
          pip install grpcio grpcio-tools pynacl
          echo "::endgroup::"

      - name: Generate gRPC Code
        run: |
          set -euo pipefail
          echo "::group::Generating gRPC code from proto files"
          cd "$GITHUB_WORKSPACE"
          
          # Use PYTHONPATH to find the strix module (NO pip install -e .)
          export PYTHONPATH="$GITHUB_WORKSPACE:${PYTHONPATH:-}"
          
          # Generate proto files using the script directly
          python strix/runtime/remote_tool_server/generate_proto.py || {
            echo "::warning::Direct script failed, trying module execution"
            python -m strix.runtime.remote_tool_server.generate_proto
          }
          
          echo "Generated gRPC code"
          ls -la strix/runtime/remote_tool_server/proto/ || true
          
          # Fix imports in generated files - gRPC tools generates absolute imports
          # that don't work with package structure. Convert to relative imports.
          PROTO_DIR="strix/runtime/remote_tool_server/proto"
          
          # Fix tool_service_pb2_grpc.py: change 'import tool_service_pb2' to 'from . import tool_service_pb2'
          if [ -f "$PROTO_DIR/tool_service_pb2_grpc.py" ]; then
            sed -i 's/^import tool_service_pb2 as/from . import tool_service_pb2 as/' "$PROTO_DIR/tool_service_pb2_grpc.py"
            echo "Fixed imports in tool_service_pb2_grpc.py"
          fi
          
          # Verify proto files are importable by starting a fresh Python process
          python -c "
          import sys
          import os
          
          # Debug: Print current working directory and PYTHONPATH
          print(f'CWD: {os.getcwd()}')
          print(f'PYTHONPATH: {os.environ.get(\"PYTHONPATH\", \"not set\")}')
          
          # Check if proto files exist on disk
          proto_path = 'strix/runtime/remote_tool_server/proto/tool_service_pb2.py'
          print(f'Proto file exists on disk: {os.path.exists(proto_path)}')
          
          # Now try the import - this is a fresh Python process so no caching issues
          try:
              from strix.runtime.remote_tool_server.proto import tool_service_pb2
              print('Direct proto import: SUCCESS')
          except ImportError as e:
              print(f'Direct proto import: FAILED - {e}')
              sys.exit(1)
          
          # Check server module
          from strix.runtime.remote_tool_server import server
          print(f'PROTO_AVAILABLE: {server.PROTO_AVAILABLE}')
          print(f'tool_service_pb2: {server.tool_service_pb2}')
          print(f'tool_service_pb2_grpc: {server.tool_service_pb2_grpc}')
          
          if not server.PROTO_AVAILABLE:
              print('ERROR: PROTO_AVAILABLE is False in fresh Python process!')
              print('This indicates the import in server.py itself is failing')
              # Try to manually debug the import
              import traceback
              try:
                  from strix.runtime.remote_tool_server.proto import tool_service_pb2
                  from strix.runtime.remote_tool_server.proto import tool_service_pb2_grpc
                  print('Manual re-import in same process: SUCCESS')
              except ImportError:
                  print('Manual re-import in same process: FAILED')
                  traceback.print_exc()
              sys.exit(1)
          print('All checks passed!')
          " || {
            echo "::error::Proto files check failed"
            exit 1
          }
          
          echo "::endgroup::"

      - name: Generate Server Token
        id: token
        run: |
          set -euo pipefail
          # Generate a secure random token for server authentication
          TOKEN=$(openssl rand -hex 32)
          echo "token=$TOKEN" >> "$GITHUB_OUTPUT"
          echo "SERVER_TOKEN=$TOKEN" >> "$GITHUB_ENV"

      - name: Start gRPC Server
        id: server
        env:
          STRIX_SERVER_PORT: ${{ env.SERVER_PORT }}
          STRIX_SERVER_TOKEN: ${{ steps.token.outputs.token }}
          STRIXDB_TOKEN: ${{ secrets.STRIXDB_TOKEN }}
          STRIX_TOOL_POOL_SIZE: "10"
        run: |
          set -euo pipefail
          echo "::group::Starting gRPC Tool Server"
          
          # Set PYTHONPATH to include workspace
          export PYTHONPATH="$GITHUB_WORKSPACE:${PYTHONPATH:-}"
          
          # Verify proto files were generated (correct path: strix/runtime not strix/strix/runtime)
          if [ ! -f "$GITHUB_WORKSPACE/strix/runtime/remote_tool_server/proto/tool_service_pb2.py" ]; then
            echo "::error::Proto files not generated"
            exit 1
          fi
          
          # Test server import first
          cd "$GITHUB_WORKSPACE"
          python -c "from strix.runtime.remote_tool_server.server import serve; print('Server module imported successfully')" || {
            echo "::error::Failed to import server module"
            python -c "from strix.runtime.remote_tool_server.server import serve" 2>&1
            exit 1
          }
          
          # Start server in background with all environment variables
          # Use module execution with explicit PYTHONPATH
          cd "$GITHUB_WORKSPACE"
          nohup env \
            PYTHONPATH="$GITHUB_WORKSPACE:${PYTHONPATH:-}" \
            STRIX_SERVER_PORT="$STRIX_SERVER_PORT" \
            STRIX_SERVER_TOKEN="$STRIX_SERVER_TOKEN" \
            STRIXDB_TOKEN="$STRIXDB_TOKEN" \
            STRIX_TOOL_POOL_SIZE="$STRIX_TOOL_POOL_SIZE" \
            python -m strix.runtime.remote_tool_server.server > /tmp/server.log 2>&1 &
          SERVER_PID=$!
          echo "$SERVER_PID" > /tmp/server.pid
          
          # Wait for server to start and check logs
          sleep 8
          
          # Check server logs for errors
          if [ -f /tmp/server.log ]; then
            echo "Server startup logs:"
            cat /tmp/server.log || true
          fi
          
          # Check if server is running
          if ! kill -0 $SERVER_PID 2>/dev/null; then
            echo "::error::Server failed to start (PID: $SERVER_PID)"
            if [ -f /tmp/server.log ]; then
              echo "Full server logs:"
              cat /tmp/server.log
            fi
            exit 1
          fi
          
          # Test server health (if possible)
          echo "Server started with PID: $SERVER_PID"
          echo "server_pid=$SERVER_PID" >> "$GITHUB_OUTPUT"
          echo "::endgroup::"

      - name: Start Cloudflared Tunnel
        id: tunnel
        run: |
          set -euo pipefail
          echo "::group::Starting Cloudflared Tunnel"
          
          # Start cloudflared tunnel pointing to gRPC server
          # Note: gRPC requires TLS, so we use cloudflared's HTTPS tunnel
          nohup cloudflared tunnel --url http://localhost:${{ env.SERVER_PORT }} > /tmp/tunnel.log 2>&1 &
          TUNNEL_PID=$!
          echo "$TUNNEL_PID" > /tmp/tunnel.pid
          
          # Wait for tunnel to establish
          sleep 10
          
          # Extract tunnel URL
          DASHBOARD_URL=""
          for i in {1..30}; do
            DASHBOARD_URL=$(grep -oE 'https://[a-zA-Z0-9-]+\.trycloudflare\.com' /tmp/tunnel.log | head -1 || true)
            if [ -n "$DASHBOARD_URL" ]; then
              break
            fi
            echo "Waiting for tunnel URL... (attempt $i/30)"
            sleep 2
          done
          
          if [ -z "$DASHBOARD_URL" ]; then
            echo "::error::Could not establish tunnel"
            cat /tmp/tunnel.log || true
            exit 1
          fi
          
          # Extract hostname for gRPC (remove https://)
          TUNNEL_HOST=$(echo "$DASHBOARD_URL" | sed 's|https://||')
          
          echo ""
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  ðŸŒ REMOTE TOOL SERVER TUNNEL URL                           â•‘"
          echo "â•‘                                                              â•‘"
          echo "â•‘  $DASHBOARD_URL"
          echo "â•‘                                                              â•‘"
          echo "â•‘  gRPC Host: $TUNNEL_HOST"
          echo "â•‘  Port: 443 (HTTPS/TLS)                                       â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          
          echo "tunnel_url=$DASHBOARD_URL" >> "$GITHUB_OUTPUT"
          echo "tunnel_host=$TUNNEL_HOST" >> "$GITHUB_OUTPUT"
          echo "tunnel_pid=$TUNNEL_PID" >> "$GITHUB_OUTPUT"
          echo "::endgroup::"

      - name: Update CRED_TUNNEL Secret
        run: |
          set -euo pipefail
          echo "::group::Updating CRED_TUNNEL secret"
          
          TUNNEL_HOST="${{ steps.tunnel.outputs.tunnel_host }}"
          SERVER_TOKEN="${{ steps.token.outputs.token }}"
          SERVER_TOKEN_SECRET="${{ secrets.SERVER_TOKEN }}"
          
          if [ -z "$TUNNEL_HOST" ]; then
            echo "::error::Tunnel host not available"
            exit 1
          fi
          
          if [ -z "$SERVER_TOKEN_SECRET" ]; then
            echo "::warning::SERVER_TOKEN secret not set. Cannot update CRED_TUNNEL automatically."
            echo "Please manually set CRED_TUNNEL secret to: $TUNNEL_HOST:443"
            echo "And set STRIX_SERVER_TOKEN secret to: $SERVER_TOKEN"
            echo "::endgroup::"
            exit 0
          fi
          
          # Format: host:port for gRPC
          CRED_VALUE="$TUNNEL_HOST:443"
          
          # Install PyNaCl for secret encryption
          pip install pynacl
          
          # Extract repo name from github.repository (format: owner/repo)
          REPO_NAME=$(echo "${{ github.repository }}" | cut -d'/' -f2)
          
          # Update CRED_TUNNEL secret
          python -m strix.runtime.remote_tool_server.update_secret \
            "$SERVER_TOKEN_SECRET" \
            "${{ github.repository_owner }}" \
            "$REPO_NAME" \
            "CRED_TUNNEL" \
            "$CRED_VALUE"
          
          # Update STRIX_SERVER_TOKEN secret
          python -m strix.runtime.remote_tool_server.update_secret \
            "$SERVER_TOKEN_SECRET" \
            "${{ github.repository_owner }}" \
            "$REPO_NAME" \
            "STRIX_SERVER_TOKEN" \
            "$SERVER_TOKEN"
          
          echo "âœ“ Secrets updated successfully"
          echo "::endgroup::"

      - name: Monitor Server Health
        run: |
          set -euo pipefail
          echo "::group::Monitoring Server Health"
          
          SERVER_PID="${{ steps.server.outputs.server_pid }}"
          TUNNEL_HOST="${{ steps.tunnel.outputs.tunnel_host }}"
          SERVER_TIMEOUT_MINUTES="${{ env.SERVER_TIMEOUT }}"
          SERVER_TIMEOUT_SECONDS=$((SERVER_TIMEOUT_MINUTES * 60))
          
          # Export for Python script
          export TUNNEL_HOST
          
          if [ -z "$SERVER_PID" ]; then
            echo "::error::Server PID not available"
            exit 1
          fi
          
          # Health check interval (every 5 minutes)
          HEALTH_CHECK_INTERVAL=300
          ELAPSED=0
          FAILED_CHECKS=0
          MAX_FAILED_CHECKS=3
          
          while [ $ELAPSED -lt $SERVER_TIMEOUT_SECONDS ]; do
            # Check if server process is still running
            if ! kill -0 "$SERVER_PID" 2>/dev/null; then
              echo "::error::Server process died (PID: $SERVER_PID)"
              if [ -f /tmp/server.log ]; then
                echo "Last 50 lines of server log:"
                tail -50 /tmp/server.log || true
              fi
              exit 1
            fi
            
            # Try to check server health via gRPC if tunnel is available
            if [ -n "$TUNNEL_HOST" ] && [ $((ELAPSED % HEALTH_CHECK_INTERVAL)) -eq 0 ]; then
              echo "Performing health check (elapsed: ${ELAPSED}s)..."
              
              # Create temporary health check script
              cat > /tmp/health_check.py << 'HEALTH_SCRIPT'
import grpc
import sys
import os

try:
  from strix.runtime.remote_tool_server.proto import tool_service_pb2, tool_service_pb2_grpc
  
  tunnel_host = os.environ.get('TUNNEL_HOST', '')
  if not tunnel_host:
    print('TUNNEL_HOST not set')
    sys.exit(1)
  
  server_url = f'{tunnel_host}:443'
  credentials = grpc.ssl_channel_credentials()
  channel = grpc.secure_channel(server_url, credentials)
  stub = tool_service_pb2_grpc.ToolServiceStub(channel)
  
  request = tool_service_pb2.HealthRequest()
  response = stub.HealthCheck(request, timeout=10)
  
  if response.healthy:
    print(f'âœ“ Server healthy: {response.tool_count} tools, {response.registered_agents} agents')
    sys.exit(0)
  else:
    print('âœ— Server unhealthy')
    sys.exit(1)
except Exception as e:
  print(f'Health check failed: {e}')
  sys.exit(1)
finally:
  try:
    channel.close()
  except:
    pass
HEALTH_SCRIPT
              
              # Run health check
              python3 /tmp/health_check.py || HEALTH_CHECK_RESULT=$?
              
              if [ $HEALTH_CHECK_RESULT -ne 0 ]; then
                FAILED_CHECKS=$((FAILED_CHECKS + 1))
                echo "::warning::Health check failed (${FAILED_CHECKS}/${MAX_FAILED_CHECKS})"
                
                if [ $FAILED_CHECKS -ge $MAX_FAILED_CHECKS ]; then
                  echo "::error::Server health checks failed ${MAX_FAILED_CHECKS} times. Server may be unhealthy."
                  if [ -f /tmp/server.log ]; then
                    echo "Recent server logs:"
                    tail -100 /tmp/server.log || true
                  fi
                  # Don't exit - let it continue but log the issue
                fi
              else
                FAILED_CHECKS=0  # Reset on success
              fi
            fi
            
            # Sleep for 30 seconds before next check
            sleep 30
            ELAPSED=$((ELAPSED + 30))
            
            # Log progress every 5 minutes
            if [ $((ELAPSED % 300)) -eq 0 ]; then
              MINUTES=$((ELAPSED / 60))
              echo "Server running for ${MINUTES} minutes (${ELAPSED}/${SERVER_TIMEOUT_SECONDS}s)"
            fi
          done
          
          echo "Server timeout reached (${SERVER_TIMEOUT_MINUTES} minutes)"
          echo "::endgroup::"

      - name: Wait for Server Timeout
        timeout-minutes: ${{ fromJson(github.event.inputs.server_timeout || '120') }}
        run: |
          set -euo pipefail
          echo "::group::Server Running (waiting for timeout or manual stop)"
          
          SERVER_PID=$(cat /tmp/server.pid)
          TUNNEL_PID=$(cat /tmp/tunnel.pid)
          
          echo "Server PID: $SERVER_PID"
          echo "Tunnel PID: $TUNNEL_PID"
          echo "Server will run until timeout or manual cancellation"
          
          # Monitor server health
          while kill -0 $SERVER_PID 2>/dev/null; do
            sleep 30
            echo "Server still running... $(date)"
          done
          
          echo "Server stopped"
          echo "::endgroup::"

      - name: Stop Server and Tunnel
        if: always()
        run: |
          set -euo pipefail
          echo "::group::Stopping Server and Tunnel"
          
          if [ -f /tmp/tunnel.pid ]; then
            TUNNEL_PID=$(cat /tmp/tunnel.pid)
            kill $TUNNEL_PID 2>/dev/null || true
            echo "Tunnel stopped"
          fi
          
          if [ -f /tmp/server.pid ]; then
            SERVER_PID=$(cat /tmp/server.pid)
            kill $SERVER_PID 2>/dev/null || true
            echo "Server stopped"
          fi
          
          # Show logs
          if [ -f /tmp/server.log ]; then
            echo "Server logs:"
            tail -50 /tmp/server.log || true
          fi
          
          if [ -f /tmp/tunnel.log ]; then
            echo "Tunnel logs:"
            tail -50 /tmp/tunnel.log || true
          fi
          
          echo "::endgroup::"
